{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "17\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8a464babe09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "x=10\n",
    "print(x)\n",
    "print(x+5)\n",
    "y=x+7\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 0 에서부터 숫자를 만들어서 10개의 variable(변수)가 생성됩니다.\n",
    "\n",
    "for n in range(10):\n",
    "    print(n)\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squre of 0 is 0\n",
      "The squre of 1 is 1\n",
      "The squre of 2 is 4\n",
      "The squre of 3 is 9\n",
      "The squre of 4 is 16\n",
      "The squre of 5 is 25\n",
      "The squre of 6 is 36\n",
      "The squre of 7 is 49\n",
      "The squre of 8 is 64\n",
      "The squre of 9 is 81\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    print(\"The squre of\", n ,\"is\", n*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squre of 0 is 0\n",
      "The squre of 1 is 1\n",
      "The squre of 2 is 4\n",
      "The squre of 3 is 9\n",
      "The squre of 4 is 16\n",
      "The squre of 5 is 25\n",
      "The squre of 6 is 36\n",
      "The squre of 7 is 49\n",
      "The squre of 8 is 64\n",
      "The squre of 9 is 81\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    print(\"The squre of\", n ,\"is\", n*n)\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squre of 0 is 0\n",
      "The squre of 1 is 1\n",
      "The squre of 2 is 4\n",
      "The squre of 3 is 9\n",
      "The squre of 4 is 16\n",
      "The squre of 5 is 25\n",
      "The squre of 6 is 36\n",
      "The squre of 7 is 49\n",
      "The squre of 8 is 64\n",
      "The squre of 9 is 81\n",
      "The squre of 10 is 100\n",
      "The squre of 11 is 121\n",
      "The squre of 12 is 144\n",
      "The squre of 13 is 169\n",
      "The squre of 14 is 196\n",
      "The squre of 15 is 225\n",
      "The squre of 16 is 256\n",
      "The squre of 17 is 289\n",
      "The squre of 18 is 324\n",
      "The squre of 19 is 361\n",
      "The squre of 20 is 400\n",
      "The squre of 21 is 441\n",
      "The squre of 22 is 484\n",
      "The squre of 23 is 529\n",
      "The squre of 24 is 576\n",
      "The squre of 25 is 625\n",
      "The squre of 26 is 676\n",
      "The squre of 27 is 729\n",
      "The squre of 28 is 784\n",
      "The squre of 29 is 841\n",
      "The squre of 30 is 900\n",
      "The squre of 31 is 961\n",
      "The squre of 32 is 1024\n",
      "The squre of 33 is 1089\n",
      "The squre of 34 is 1156\n",
      "The squre of 35 is 1225\n",
      "The squre of 36 is 1296\n",
      "The squre of 37 is 1369\n",
      "The squre of 38 is 1444\n",
      "The squre of 39 is 1521\n",
      "The squre of 40 is 1600\n",
      "The squre of 41 is 1681\n",
      "The squre of 42 is 1764\n",
      "The squre of 43 is 1849\n",
      "The squre of 44 is 1936\n",
      "The squre of 45 is 2025\n",
      "The squre of 46 is 2116\n",
      "The squre of 47 is 2209\n",
      "The squre of 48 is 2304\n",
      "The squre of 49 is 2401\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for n in range(50):\n",
    "    print(\"The squre of\", n ,\"is\", n*n)\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squre of 0 is 0\n",
      "The squre of 1 is 1\n",
      "The squre of 2 is 4\n",
      "The squre of 3 is 9\n",
      "The squre of 4 is 16\n",
      "The squre of 5 is 25\n",
      "The squre of 6 is 36\n",
      "The squre of 7 is 49\n",
      "The squre of 8 is 64\n",
      "The squre of 9 is 81\n",
      "The squre of 10 is 100\n",
      "The squre of 11 is 121\n",
      "The squre of 12 is 144\n",
      "The squre of 13 is 169\n",
      "The squre of 14 is 196\n",
      "The squre of 15 is 225\n",
      "The squre of 16 is 256\n",
      "The squre of 17 is 289\n",
      "The squre of 18 is 324\n",
      "The squre of 19 is 361\n",
      "The squre of 20 is 400\n",
      "The squre of 21 is 441\n",
      "The squre of 22 is 484\n",
      "The squre of 23 is 529\n",
      "The squre of 24 is 576\n",
      "The squre of 25 is 625\n",
      "The squre of 26 is 676\n",
      "The squre of 27 is 729\n",
      "The squre of 28 is 784\n",
      "The squre of 29 is 841\n",
      "The squre of 30 is 900\n",
      "The squre of 31 is 961\n",
      "The squre of 32 is 1024\n",
      "The squre of 33 is 1089\n",
      "The squre of 34 is 1156\n",
      "The squre of 35 is 1225\n",
      "The squre of 36 is 1296\n",
      "The squre of 37 is 1369\n",
      "The squre of 38 is 1444\n",
      "The squre of 39 is 1521\n",
      "The squre of 40 is 1600\n",
      "The squre of 41 is 1681\n",
      "The squre of 42 is 1764\n",
      "The squre of 43 is 1849\n",
      "The squre of 44 is 1936\n",
      "The squre of 45 is 2025\n",
      "The squre of 46 is 2116\n",
      "The squre of 47 is 2209\n",
      "The squre of 48 is 2304\n",
      "The squre of 49 is 2401\n",
      "The squre of 50 is 2500\n",
      "The squre of 51 is 2601\n",
      "The squre of 52 is 2704\n",
      "The squre of 53 is 2809\n",
      "The squre of 54 is 2916\n",
      "The squre of 55 is 3025\n",
      "The squre of 56 is 3136\n",
      "The squre of 57 is 3249\n",
      "The squre of 58 is 3364\n",
      "The squre of 59 is 3481\n",
      "The squre of 60 is 3600\n",
      "The squre of 61 is 3721\n",
      "The squre of 62 is 3844\n",
      "The squre of 63 is 3969\n",
      "The squre of 64 is 4096\n",
      "The squre of 65 is 4225\n",
      "The squre of 66 is 4356\n",
      "The squre of 67 is 4489\n",
      "The squre of 68 is 4624\n",
      "The squre of 69 is 4761\n",
      "The squre of 70 is 4900\n",
      "The squre of 71 is 5041\n",
      "The squre of 72 is 5184\n",
      "The squre of 73 is 5329\n",
      "The squre of 74 is 5476\n",
      "The squre of 75 is 5625\n",
      "The squre of 76 is 5776\n",
      "The squre of 77 is 5929\n",
      "The squre of 78 is 6084\n",
      "The squre of 79 is 6241\n",
      "The squre of 80 is 6400\n",
      "The squre of 81 is 6561\n",
      "The squre of 82 is 6724\n",
      "The squre of 83 is 6889\n",
      "The squre of 84 is 7056\n",
      "The squre of 85 is 7225\n",
      "The squre of 86 is 7396\n",
      "The squre of 87 is 7569\n",
      "The squre of 88 is 7744\n",
      "The squre of 89 is 7921\n",
      "The squre of 90 is 8100\n",
      "The squre of 91 is 8281\n",
      "The squre of 92 is 8464\n",
      "The squre of 93 is 8649\n",
      "The squre of 94 is 8836\n",
      "The squre of 95 is 9025\n",
      "The squre of 96 is 9216\n",
      "The squre of 97 is 9409\n",
      "The squre of 98 is 9604\n",
      "The squre of 99 is 9801\n",
      "The squre of 100 is 10000\n",
      "The squre of 101 is 10201\n",
      "The squre of 102 is 10404\n",
      "The squre of 103 is 10609\n",
      "The squre of 104 is 10816\n",
      "The squre of 105 is 11025\n",
      "The squre of 106 is 11236\n",
      "The squre of 107 is 11449\n",
      "The squre of 108 is 11664\n",
      "The squre of 109 is 11881\n",
      "The squre of 110 is 12100\n",
      "The squre of 111 is 12321\n",
      "The squre of 112 is 12544\n",
      "The squre of 113 is 12769\n",
      "The squre of 114 is 12996\n",
      "The squre of 115 is 13225\n",
      "The squre of 116 is 13456\n",
      "The squre of 117 is 13689\n",
      "The squre of 118 is 13924\n",
      "The squre of 119 is 14161\n",
      "The squre of 120 is 14400\n",
      "The squre of 121 is 14641\n",
      "The squre of 122 is 14884\n",
      "The squre of 123 is 15129\n",
      "The squre of 124 is 15376\n",
      "The squre of 125 is 15625\n",
      "The squre of 126 is 15876\n",
      "The squre of 127 is 16129\n",
      "The squre of 128 is 16384\n",
      "The squre of 129 is 16641\n",
      "The squre of 130 is 16900\n",
      "The squre of 131 is 17161\n",
      "The squre of 132 is 17424\n",
      "The squre of 133 is 17689\n",
      "The squre of 134 is 17956\n",
      "The squre of 135 is 18225\n",
      "The squre of 136 is 18496\n",
      "The squre of 137 is 18769\n",
      "The squre of 138 is 19044\n",
      "The squre of 139 is 19321\n",
      "The squre of 140 is 19600\n",
      "The squre of 141 is 19881\n",
      "The squre of 142 is 20164\n",
      "The squre of 143 is 20449\n",
      "The squre of 144 is 20736\n",
      "The squre of 145 is 21025\n",
      "The squre of 146 is 21316\n",
      "The squre of 147 is 21609\n",
      "The squre of 148 is 21904\n",
      "The squre of 149 is 22201\n",
      "The squre of 150 is 22500\n",
      "The squre of 151 is 22801\n",
      "The squre of 152 is 23104\n",
      "The squre of 153 is 23409\n",
      "The squre of 154 is 23716\n",
      "The squre of 155 is 24025\n",
      "The squre of 156 is 24336\n",
      "The squre of 157 is 24649\n",
      "The squre of 158 is 24964\n",
      "The squre of 159 is 25281\n",
      "The squre of 160 is 25600\n",
      "The squre of 161 is 25921\n",
      "The squre of 162 is 26244\n",
      "The squre of 163 is 26569\n",
      "The squre of 164 is 26896\n",
      "The squre of 165 is 27225\n",
      "The squre of 166 is 27556\n",
      "The squre of 167 is 27889\n",
      "The squre of 168 is 28224\n",
      "The squre of 169 is 28561\n",
      "The squre of 170 is 28900\n",
      "The squre of 171 is 29241\n",
      "The squre of 172 is 29584\n",
      "The squre of 173 is 29929\n",
      "The squre of 174 is 30276\n",
      "The squre of 175 is 30625\n",
      "The squre of 176 is 30976\n",
      "The squre of 177 is 31329\n",
      "The squre of 178 is 31684\n",
      "The squre of 179 is 32041\n",
      "The squre of 180 is 32400\n",
      "The squre of 181 is 32761\n",
      "The squre of 182 is 33124\n",
      "The squre of 183 is 33489\n",
      "The squre of 184 is 33856\n",
      "The squre of 185 is 34225\n",
      "The squre of 186 is 34596\n",
      "The squre of 187 is 34969\n",
      "The squre of 188 is 35344\n",
      "The squre of 189 is 35721\n",
      "The squre of 190 is 36100\n",
      "The squre of 191 is 36481\n",
      "The squre of 192 is 36864\n",
      "The squre of 193 is 37249\n",
      "The squre of 194 is 37636\n",
      "The squre of 195 is 38025\n",
      "The squre of 196 is 38416\n",
      "The squre of 197 is 38809\n",
      "The squre of 198 is 39204\n",
      "The squre of 199 is 39601\n",
      "The squre of 200 is 40000\n",
      "The squre of 201 is 40401\n",
      "The squre of 202 is 40804\n",
      "The squre of 203 is 41209\n",
      "The squre of 204 is 41616\n",
      "The squre of 205 is 42025\n",
      "The squre of 206 is 42436\n",
      "The squre of 207 is 42849\n",
      "The squre of 208 is 43264\n",
      "The squre of 209 is 43681\n",
      "The squre of 210 is 44100\n",
      "The squre of 211 is 44521\n",
      "The squre of 212 is 44944\n",
      "The squre of 213 is 45369\n",
      "The squre of 214 is 45796\n",
      "The squre of 215 is 46225\n",
      "The squre of 216 is 46656\n",
      "The squre of 217 is 47089\n",
      "The squre of 218 is 47524\n",
      "The squre of 219 is 47961\n",
      "The squre of 220 is 48400\n",
      "The squre of 221 is 48841\n",
      "The squre of 222 is 49284\n",
      "The squre of 223 is 49729\n",
      "The squre of 224 is 50176\n",
      "The squre of 225 is 50625\n",
      "The squre of 226 is 51076\n",
      "The squre of 227 is 51529\n",
      "The squre of 228 is 51984\n",
      "The squre of 229 is 52441\n",
      "The squre of 230 is 52900\n",
      "The squre of 231 is 53361\n",
      "The squre of 232 is 53824\n",
      "The squre of 233 is 54289\n",
      "The squre of 234 is 54756\n",
      "The squre of 235 is 55225\n",
      "The squre of 236 is 55696\n",
      "The squre of 237 is 56169\n",
      "The squre of 238 is 56644\n",
      "The squre of 239 is 57121\n",
      "The squre of 240 is 57600\n",
      "The squre of 241 is 58081\n",
      "The squre of 242 is 58564\n",
      "The squre of 243 is 59049\n",
      "The squre of 244 is 59536\n",
      "The squre of 245 is 60025\n",
      "The squre of 246 is 60516\n",
      "The squre of 247 is 61009\n",
      "The squre of 248 is 61504\n",
      "The squre of 249 is 62001\n",
      "The squre of 250 is 62500\n",
      "The squre of 251 is 63001\n",
      "The squre of 252 is 63504\n",
      "The squre of 253 is 64009\n",
      "The squre of 254 is 64516\n",
      "The squre of 255 is 65025\n",
      "The squre of 256 is 65536\n",
      "The squre of 257 is 66049\n",
      "The squre of 258 is 66564\n",
      "The squre of 259 is 67081\n",
      "The squre of 260 is 67600\n",
      "The squre of 261 is 68121\n",
      "The squre of 262 is 68644\n",
      "The squre of 263 is 69169\n",
      "The squre of 264 is 69696\n",
      "The squre of 265 is 70225\n",
      "The squre of 266 is 70756\n",
      "The squre of 267 is 71289\n",
      "The squre of 268 is 71824\n",
      "The squre of 269 is 72361\n",
      "The squre of 270 is 72900\n",
      "The squre of 271 is 73441\n",
      "The squre of 272 is 73984\n",
      "The squre of 273 is 74529\n",
      "The squre of 274 is 75076\n",
      "The squre of 275 is 75625\n",
      "The squre of 276 is 76176\n",
      "The squre of 277 is 76729\n",
      "The squre of 278 is 77284\n",
      "The squre of 279 is 77841\n",
      "The squre of 280 is 78400\n",
      "The squre of 281 is 78961\n",
      "The squre of 282 is 79524\n",
      "The squre of 283 is 80089\n",
      "The squre of 284 is 80656\n",
      "The squre of 285 is 81225\n",
      "The squre of 286 is 81796\n",
      "The squre of 287 is 82369\n",
      "The squre of 288 is 82944\n",
      "The squre of 289 is 83521\n",
      "The squre of 290 is 84100\n",
      "The squre of 291 is 84681\n",
      "The squre of 292 is 85264\n",
      "The squre of 293 is 85849\n",
      "The squre of 294 is 86436\n",
      "The squre of 295 is 87025\n",
      "The squre of 296 is 87616\n",
      "The squre of 297 is 88209\n",
      "The squre of 298 is 88804\n",
      "The squre of 299 is 89401\n",
      "The squre of 300 is 90000\n",
      "The squre of 301 is 90601\n",
      "The squre of 302 is 91204\n",
      "The squre of 303 is 91809\n",
      "The squre of 304 is 92416\n",
      "The squre of 305 is 93025\n",
      "The squre of 306 is 93636\n",
      "The squre of 307 is 94249\n",
      "The squre of 308 is 94864\n",
      "The squre of 309 is 95481\n",
      "The squre of 310 is 96100\n",
      "The squre of 311 is 96721\n",
      "The squre of 312 is 97344\n",
      "The squre of 313 is 97969\n",
      "The squre of 314 is 98596\n",
      "The squre of 315 is 99225\n",
      "The squre of 316 is 99856\n",
      "The squre of 317 is 100489\n",
      "The squre of 318 is 101124\n",
      "The squre of 319 is 101761\n",
      "The squre of 320 is 102400\n",
      "The squre of 321 is 103041\n",
      "The squre of 322 is 103684\n",
      "The squre of 323 is 104329\n",
      "The squre of 324 is 104976\n",
      "The squre of 325 is 105625\n",
      "The squre of 326 is 106276\n",
      "The squre of 327 is 106929\n",
      "The squre of 328 is 107584\n",
      "The squre of 329 is 108241\n",
      "The squre of 330 is 108900\n",
      "The squre of 331 is 109561\n",
      "The squre of 332 is 110224\n",
      "The squre of 333 is 110889\n",
      "The squre of 334 is 111556\n",
      "The squre of 335 is 112225\n",
      "The squre of 336 is 112896\n",
      "The squre of 337 is 113569\n",
      "The squre of 338 is 114244\n",
      "The squre of 339 is 114921\n",
      "The squre of 340 is 115600\n",
      "The squre of 341 is 116281\n",
      "The squre of 342 is 116964\n",
      "The squre of 343 is 117649\n",
      "The squre of 344 is 118336\n",
      "The squre of 345 is 119025\n",
      "The squre of 346 is 119716\n",
      "The squre of 347 is 120409\n",
      "The squre of 348 is 121104\n",
      "The squre of 349 is 121801\n",
      "The squre of 350 is 122500\n",
      "The squre of 351 is 123201\n",
      "The squre of 352 is 123904\n",
      "The squre of 353 is 124609\n",
      "The squre of 354 is 125316\n",
      "The squre of 355 is 126025\n",
      "The squre of 356 is 126736\n",
      "The squre of 357 is 127449\n",
      "The squre of 358 is 128164\n",
      "The squre of 359 is 128881\n",
      "The squre of 360 is 129600\n",
      "The squre of 361 is 130321\n",
      "The squre of 362 is 131044\n",
      "The squre of 363 is 131769\n",
      "The squre of 364 is 132496\n",
      "The squre of 365 is 133225\n",
      "The squre of 366 is 133956\n",
      "The squre of 367 is 134689\n",
      "The squre of 368 is 135424\n",
      "The squre of 369 is 136161\n",
      "The squre of 370 is 136900\n",
      "The squre of 371 is 137641\n",
      "The squre of 372 is 138384\n",
      "The squre of 373 is 139129\n",
      "The squre of 374 is 139876\n",
      "The squre of 375 is 140625\n",
      "The squre of 376 is 141376\n",
      "The squre of 377 is 142129\n",
      "The squre of 378 is 142884\n",
      "The squre of 379 is 143641\n",
      "The squre of 380 is 144400\n",
      "The squre of 381 is 145161\n",
      "The squre of 382 is 145924\n",
      "The squre of 383 is 146689\n",
      "The squre of 384 is 147456\n",
      "The squre of 385 is 148225\n",
      "The squre of 386 is 148996\n",
      "The squre of 387 is 149769\n",
      "The squre of 388 is 150544\n",
      "The squre of 389 is 151321\n",
      "The squre of 390 is 152100\n",
      "The squre of 391 is 152881\n",
      "The squre of 392 is 153664\n",
      "The squre of 393 is 154449\n",
      "The squre of 394 is 155236\n",
      "The squre of 395 is 156025\n",
      "The squre of 396 is 156816\n",
      "The squre of 397 is 157609\n",
      "The squre of 398 is 158404\n",
      "The squre of 399 is 159201\n",
      "The squre of 400 is 160000\n",
      "The squre of 401 is 160801\n",
      "The squre of 402 is 161604\n",
      "The squre of 403 is 162409\n",
      "The squre of 404 is 163216\n",
      "The squre of 405 is 164025\n",
      "The squre of 406 is 164836\n",
      "The squre of 407 is 165649\n",
      "The squre of 408 is 166464\n",
      "The squre of 409 is 167281\n",
      "The squre of 410 is 168100\n",
      "The squre of 411 is 168921\n",
      "The squre of 412 is 169744\n",
      "The squre of 413 is 170569\n",
      "The squre of 414 is 171396\n",
      "The squre of 415 is 172225\n",
      "The squre of 416 is 173056\n",
      "The squre of 417 is 173889\n",
      "The squre of 418 is 174724\n",
      "The squre of 419 is 175561\n",
      "The squre of 420 is 176400\n",
      "The squre of 421 is 177241\n",
      "The squre of 422 is 178084\n",
      "The squre of 423 is 178929\n",
      "The squre of 424 is 179776\n",
      "The squre of 425 is 180625\n",
      "The squre of 426 is 181476\n",
      "The squre of 427 is 182329\n",
      "The squre of 428 is 183184\n",
      "The squre of 429 is 184041\n",
      "The squre of 430 is 184900\n",
      "The squre of 431 is 185761\n",
      "The squre of 432 is 186624\n",
      "The squre of 433 is 187489\n",
      "The squre of 434 is 188356\n",
      "The squre of 435 is 189225\n",
      "The squre of 436 is 190096\n",
      "The squre of 437 is 190969\n",
      "The squre of 438 is 191844\n",
      "The squre of 439 is 192721\n",
      "The squre of 440 is 193600\n",
      "The squre of 441 is 194481\n",
      "The squre of 442 is 195364\n",
      "The squre of 443 is 196249\n",
      "The squre of 444 is 197136\n",
      "The squre of 445 is 198025\n",
      "The squre of 446 is 198916\n",
      "The squre of 447 is 199809\n",
      "The squre of 448 is 200704\n",
      "The squre of 449 is 201601\n",
      "The squre of 450 is 202500\n",
      "The squre of 451 is 203401\n",
      "The squre of 452 is 204304\n",
      "The squre of 453 is 205209\n",
      "The squre of 454 is 206116\n",
      "The squre of 455 is 207025\n",
      "The squre of 456 is 207936\n",
      "The squre of 457 is 208849\n",
      "The squre of 458 is 209764\n",
      "The squre of 459 is 210681\n",
      "The squre of 460 is 211600\n",
      "The squre of 461 is 212521\n",
      "The squre of 462 is 213444\n",
      "The squre of 463 is 214369\n",
      "The squre of 464 is 215296\n",
      "The squre of 465 is 216225\n",
      "The squre of 466 is 217156\n",
      "The squre of 467 is 218089\n",
      "The squre of 468 is 219024\n",
      "The squre of 469 is 219961\n",
      "The squre of 470 is 220900\n",
      "The squre of 471 is 221841\n",
      "The squre of 472 is 222784\n",
      "The squre of 473 is 223729\n",
      "The squre of 474 is 224676\n",
      "The squre of 475 is 225625\n",
      "The squre of 476 is 226576\n",
      "The squre of 477 is 227529\n",
      "The squre of 478 is 228484\n",
      "The squre of 479 is 229441\n",
      "The squre of 480 is 230400\n",
      "The squre of 481 is 231361\n",
      "The squre of 482 is 232324\n",
      "The squre of 483 is 233289\n",
      "The squre of 484 is 234256\n",
      "The squre of 485 is 235225\n",
      "The squre of 486 is 236196\n",
      "The squre of 487 is 237169\n",
      "The squre of 488 is 238144\n",
      "The squre of 489 is 239121\n",
      "The squre of 490 is 240100\n",
      "The squre of 491 is 241081\n",
      "The squre of 492 is 242064\n",
      "The squre of 493 is 243049\n",
      "The squre of 494 is 244036\n",
      "The squre of 495 is 245025\n",
      "The squre of 496 is 246016\n",
      "The squre of 497 is 247009\n",
      "The squre of 498 is 248004\n",
      "The squre of 499 is 249001\n",
      "The squre of 500 is 250000\n",
      "The squre of 501 is 251001\n",
      "The squre of 502 is 252004\n",
      "The squre of 503 is 253009\n",
      "The squre of 504 is 254016\n",
      "The squre of 505 is 255025\n",
      "The squre of 506 is 256036\n",
      "The squre of 507 is 257049\n",
      "The squre of 508 is 258064\n",
      "The squre of 509 is 259081\n",
      "The squre of 510 is 260100\n",
      "The squre of 511 is 261121\n",
      "The squre of 512 is 262144\n",
      "The squre of 513 is 263169\n",
      "The squre of 514 is 264196\n",
      "The squre of 515 is 265225\n",
      "The squre of 516 is 266256\n",
      "The squre of 517 is 267289\n",
      "The squre of 518 is 268324\n",
      "The squre of 519 is 269361\n",
      "The squre of 520 is 270400\n",
      "The squre of 521 is 271441\n",
      "The squre of 522 is 272484\n",
      "The squre of 523 is 273529\n",
      "The squre of 524 is 274576\n",
      "The squre of 525 is 275625\n",
      "The squre of 526 is 276676\n",
      "The squre of 527 is 277729\n",
      "The squre of 528 is 278784\n",
      "The squre of 529 is 279841\n",
      "The squre of 530 is 280900\n",
      "The squre of 531 is 281961\n",
      "The squre of 532 is 283024\n",
      "The squre of 533 is 284089\n",
      "The squre of 534 is 285156\n",
      "The squre of 535 is 286225\n",
      "The squre of 536 is 287296\n",
      "The squre of 537 is 288369\n",
      "The squre of 538 is 289444\n",
      "The squre of 539 is 290521\n",
      "The squre of 540 is 291600\n",
      "The squre of 541 is 292681\n",
      "The squre of 542 is 293764\n",
      "The squre of 543 is 294849\n",
      "The squre of 544 is 295936\n",
      "The squre of 545 is 297025\n",
      "The squre of 546 is 298116\n",
      "The squre of 547 is 299209\n",
      "The squre of 548 is 300304\n",
      "The squre of 549 is 301401\n",
      "The squre of 550 is 302500\n",
      "The squre of 551 is 303601\n",
      "The squre of 552 is 304704\n",
      "The squre of 553 is 305809\n",
      "The squre of 554 is 306916\n",
      "The squre of 555 is 308025\n",
      "The squre of 556 is 309136\n",
      "The squre of 557 is 310249\n",
      "The squre of 558 is 311364\n",
      "The squre of 559 is 312481\n",
      "The squre of 560 is 313600\n",
      "The squre of 561 is 314721\n",
      "The squre of 562 is 315844\n",
      "The squre of 563 is 316969\n",
      "The squre of 564 is 318096\n",
      "The squre of 565 is 319225\n",
      "The squre of 566 is 320356\n",
      "The squre of 567 is 321489\n",
      "The squre of 568 is 322624\n",
      "The squre of 569 is 323761\n",
      "The squre of 570 is 324900\n",
      "The squre of 571 is 326041\n",
      "The squre of 572 is 327184\n",
      "The squre of 573 is 328329\n",
      "The squre of 574 is 329476\n",
      "The squre of 575 is 330625\n",
      "The squre of 576 is 331776\n",
      "The squre of 577 is 332929\n",
      "The squre of 578 is 334084\n",
      "The squre of 579 is 335241\n",
      "The squre of 580 is 336400\n",
      "The squre of 581 is 337561\n",
      "The squre of 582 is 338724\n",
      "The squre of 583 is 339889\n",
      "The squre of 584 is 341056\n",
      "The squre of 585 is 342225\n",
      "The squre of 586 is 343396\n",
      "The squre of 587 is 344569\n",
      "The squre of 588 is 345744\n",
      "The squre of 589 is 346921\n",
      "The squre of 590 is 348100\n",
      "The squre of 591 is 349281\n",
      "The squre of 592 is 350464\n",
      "The squre of 593 is 351649\n",
      "The squre of 594 is 352836\n",
      "The squre of 595 is 354025\n",
      "The squre of 596 is 355216\n",
      "The squre of 597 is 356409\n",
      "The squre of 598 is 357604\n",
      "The squre of 599 is 358801\n",
      "The squre of 600 is 360000\n",
      "The squre of 601 is 361201\n",
      "The squre of 602 is 362404\n",
      "The squre of 603 is 363609\n",
      "The squre of 604 is 364816\n",
      "The squre of 605 is 366025\n",
      "The squre of 606 is 367236\n",
      "The squre of 607 is 368449\n",
      "The squre of 608 is 369664\n",
      "The squre of 609 is 370881\n",
      "The squre of 610 is 372100\n",
      "The squre of 611 is 373321\n",
      "The squre of 612 is 374544\n",
      "The squre of 613 is 375769\n",
      "The squre of 614 is 376996\n",
      "The squre of 615 is 378225\n",
      "The squre of 616 is 379456\n",
      "The squre of 617 is 380689\n",
      "The squre of 618 is 381924\n",
      "The squre of 619 is 383161\n",
      "The squre of 620 is 384400\n",
      "The squre of 621 is 385641\n",
      "The squre of 622 is 386884\n",
      "The squre of 623 is 388129\n",
      "The squre of 624 is 389376\n",
      "The squre of 625 is 390625\n",
      "The squre of 626 is 391876\n",
      "The squre of 627 is 393129\n",
      "The squre of 628 is 394384\n",
      "The squre of 629 is 395641\n",
      "The squre of 630 is 396900\n",
      "The squre of 631 is 398161\n",
      "The squre of 632 is 399424\n",
      "The squre of 633 is 400689\n",
      "The squre of 634 is 401956\n",
      "The squre of 635 is 403225\n",
      "The squre of 636 is 404496\n",
      "The squre of 637 is 405769\n",
      "The squre of 638 is 407044\n",
      "The squre of 639 is 408321\n",
      "The squre of 640 is 409600\n",
      "The squre of 641 is 410881\n",
      "The squre of 642 is 412164\n",
      "The squre of 643 is 413449\n",
      "The squre of 644 is 414736\n",
      "The squre of 645 is 416025\n",
      "The squre of 646 is 417316\n",
      "The squre of 647 is 418609\n",
      "The squre of 648 is 419904\n",
      "The squre of 649 is 421201\n",
      "The squre of 650 is 422500\n",
      "The squre of 651 is 423801\n",
      "The squre of 652 is 425104\n",
      "The squre of 653 is 426409\n",
      "The squre of 654 is 427716\n",
      "The squre of 655 is 429025\n",
      "The squre of 656 is 430336\n",
      "The squre of 657 is 431649\n",
      "The squre of 658 is 432964\n",
      "The squre of 659 is 434281\n",
      "The squre of 660 is 435600\n",
      "The squre of 661 is 436921\n",
      "The squre of 662 is 438244\n",
      "The squre of 663 is 439569\n",
      "The squre of 664 is 440896\n",
      "The squre of 665 is 442225\n",
      "The squre of 666 is 443556\n",
      "The squre of 667 is 444889\n",
      "The squre of 668 is 446224\n",
      "The squre of 669 is 447561\n",
      "The squre of 670 is 448900\n",
      "The squre of 671 is 450241\n",
      "The squre of 672 is 451584\n",
      "The squre of 673 is 452929\n",
      "The squre of 674 is 454276\n",
      "The squre of 675 is 455625\n",
      "The squre of 676 is 456976\n",
      "The squre of 677 is 458329\n",
      "The squre of 678 is 459684\n",
      "The squre of 679 is 461041\n",
      "The squre of 680 is 462400\n",
      "The squre of 681 is 463761\n",
      "The squre of 682 is 465124\n",
      "The squre of 683 is 466489\n",
      "The squre of 684 is 467856\n",
      "The squre of 685 is 469225\n",
      "The squre of 686 is 470596\n",
      "The squre of 687 is 471969\n",
      "The squre of 688 is 473344\n",
      "The squre of 689 is 474721\n",
      "The squre of 690 is 476100\n",
      "The squre of 691 is 477481\n",
      "The squre of 692 is 478864\n",
      "The squre of 693 is 480249\n",
      "The squre of 694 is 481636\n",
      "The squre of 695 is 483025\n",
      "The squre of 696 is 484416\n",
      "The squre of 697 is 485809\n",
      "The squre of 698 is 487204\n",
      "The squre of 699 is 488601\n",
      "The squre of 700 is 490000\n",
      "The squre of 701 is 491401\n",
      "The squre of 702 is 492804\n",
      "The squre of 703 is 494209\n",
      "The squre of 704 is 495616\n",
      "The squre of 705 is 497025\n",
      "The squre of 706 is 498436\n",
      "The squre of 707 is 499849\n",
      "The squre of 708 is 501264\n",
      "The squre of 709 is 502681\n",
      "The squre of 710 is 504100\n",
      "The squre of 711 is 505521\n",
      "The squre of 712 is 506944\n",
      "The squre of 713 is 508369\n",
      "The squre of 714 is 509796\n",
      "The squre of 715 is 511225\n",
      "The squre of 716 is 512656\n",
      "The squre of 717 is 514089\n",
      "The squre of 718 is 515524\n",
      "The squre of 719 is 516961\n",
      "The squre of 720 is 518400\n",
      "The squre of 721 is 519841\n",
      "The squre of 722 is 521284\n",
      "The squre of 723 is 522729\n",
      "The squre of 724 is 524176\n",
      "The squre of 725 is 525625\n",
      "The squre of 726 is 527076\n",
      "The squre of 727 is 528529\n",
      "The squre of 728 is 529984\n",
      "The squre of 729 is 531441\n",
      "The squre of 730 is 532900\n",
      "The squre of 731 is 534361\n",
      "The squre of 732 is 535824\n",
      "The squre of 733 is 537289\n",
      "The squre of 734 is 538756\n",
      "The squre of 735 is 540225\n",
      "The squre of 736 is 541696\n",
      "The squre of 737 is 543169\n",
      "The squre of 738 is 544644\n",
      "The squre of 739 is 546121\n",
      "The squre of 740 is 547600\n",
      "The squre of 741 is 549081\n",
      "The squre of 742 is 550564\n",
      "The squre of 743 is 552049\n",
      "The squre of 744 is 553536\n",
      "The squre of 745 is 555025\n",
      "The squre of 746 is 556516\n",
      "The squre of 747 is 558009\n",
      "The squre of 748 is 559504\n",
      "The squre of 749 is 561001\n",
      "The squre of 750 is 562500\n",
      "The squre of 751 is 564001\n",
      "The squre of 752 is 565504\n",
      "The squre of 753 is 567009\n",
      "The squre of 754 is 568516\n",
      "The squre of 755 is 570025\n",
      "The squre of 756 is 571536\n",
      "The squre of 757 is 573049\n",
      "The squre of 758 is 574564\n",
      "The squre of 759 is 576081\n",
      "The squre of 760 is 577600\n",
      "The squre of 761 is 579121\n",
      "The squre of 762 is 580644\n",
      "The squre of 763 is 582169\n",
      "The squre of 764 is 583696\n",
      "The squre of 765 is 585225\n",
      "The squre of 766 is 586756\n",
      "The squre of 767 is 588289\n",
      "The squre of 768 is 589824\n",
      "The squre of 769 is 591361\n",
      "The squre of 770 is 592900\n",
      "The squre of 771 is 594441\n",
      "The squre of 772 is 595984\n",
      "The squre of 773 is 597529\n",
      "The squre of 774 is 599076\n",
      "The squre of 775 is 600625\n",
      "The squre of 776 is 602176\n",
      "The squre of 777 is 603729\n",
      "The squre of 778 is 605284\n",
      "The squre of 779 is 606841\n",
      "The squre of 780 is 608400\n",
      "The squre of 781 is 609961\n",
      "The squre of 782 is 611524\n",
      "The squre of 783 is 613089\n",
      "The squre of 784 is 614656\n",
      "The squre of 785 is 616225\n",
      "The squre of 786 is 617796\n",
      "The squre of 787 is 619369\n",
      "The squre of 788 is 620944\n",
      "The squre of 789 is 622521\n",
      "The squre of 790 is 624100\n",
      "The squre of 791 is 625681\n",
      "The squre of 792 is 627264\n",
      "The squre of 793 is 628849\n",
      "The squre of 794 is 630436\n",
      "The squre of 795 is 632025\n",
      "The squre of 796 is 633616\n",
      "The squre of 797 is 635209\n",
      "The squre of 798 is 636804\n",
      "The squre of 799 is 638401\n",
      "The squre of 800 is 640000\n",
      "The squre of 801 is 641601\n",
      "The squre of 802 is 643204\n",
      "The squre of 803 is 644809\n",
      "The squre of 804 is 646416\n",
      "The squre of 805 is 648025\n",
      "The squre of 806 is 649636\n",
      "The squre of 807 is 651249\n",
      "The squre of 808 is 652864\n",
      "The squre of 809 is 654481\n",
      "The squre of 810 is 656100\n",
      "The squre of 811 is 657721\n",
      "The squre of 812 is 659344\n",
      "The squre of 813 is 660969\n",
      "The squre of 814 is 662596\n",
      "The squre of 815 is 664225\n",
      "The squre of 816 is 665856\n",
      "The squre of 817 is 667489\n",
      "The squre of 818 is 669124\n",
      "The squre of 819 is 670761\n",
      "The squre of 820 is 672400\n",
      "The squre of 821 is 674041\n",
      "The squre of 822 is 675684\n",
      "The squre of 823 is 677329\n",
      "The squre of 824 is 678976\n",
      "The squre of 825 is 680625\n",
      "The squre of 826 is 682276\n",
      "The squre of 827 is 683929\n",
      "The squre of 828 is 685584\n",
      "The squre of 829 is 687241\n",
      "The squre of 830 is 688900\n",
      "The squre of 831 is 690561\n",
      "The squre of 832 is 692224\n",
      "The squre of 833 is 693889\n",
      "The squre of 834 is 695556\n",
      "The squre of 835 is 697225\n",
      "The squre of 836 is 698896\n",
      "The squre of 837 is 700569\n",
      "The squre of 838 is 702244\n",
      "The squre of 839 is 703921\n",
      "The squre of 840 is 705600\n",
      "The squre of 841 is 707281\n",
      "The squre of 842 is 708964\n",
      "The squre of 843 is 710649\n",
      "The squre of 844 is 712336\n",
      "The squre of 845 is 714025\n",
      "The squre of 846 is 715716\n",
      "The squre of 847 is 717409\n",
      "The squre of 848 is 719104\n",
      "The squre of 849 is 720801\n",
      "The squre of 850 is 722500\n",
      "The squre of 851 is 724201\n",
      "The squre of 852 is 725904\n",
      "The squre of 853 is 727609\n",
      "The squre of 854 is 729316\n",
      "The squre of 855 is 731025\n",
      "The squre of 856 is 732736\n",
      "The squre of 857 is 734449\n",
      "The squre of 858 is 736164\n",
      "The squre of 859 is 737881\n",
      "The squre of 860 is 739600\n",
      "The squre of 861 is 741321\n",
      "The squre of 862 is 743044\n",
      "The squre of 863 is 744769\n",
      "The squre of 864 is 746496\n",
      "The squre of 865 is 748225\n",
      "The squre of 866 is 749956\n",
      "The squre of 867 is 751689\n",
      "The squre of 868 is 753424\n",
      "The squre of 869 is 755161\n",
      "The squre of 870 is 756900\n",
      "The squre of 871 is 758641\n",
      "The squre of 872 is 760384\n",
      "The squre of 873 is 762129\n",
      "The squre of 874 is 763876\n",
      "The squre of 875 is 765625\n",
      "The squre of 876 is 767376\n",
      "The squre of 877 is 769129\n",
      "The squre of 878 is 770884\n",
      "The squre of 879 is 772641\n",
      "The squre of 880 is 774400\n",
      "The squre of 881 is 776161\n",
      "The squre of 882 is 777924\n",
      "The squre of 883 is 779689\n",
      "The squre of 884 is 781456\n",
      "The squre of 885 is 783225\n",
      "The squre of 886 is 784996\n",
      "The squre of 887 is 786769\n",
      "The squre of 888 is 788544\n",
      "The squre of 889 is 790321\n",
      "The squre of 890 is 792100\n",
      "The squre of 891 is 793881\n",
      "The squre of 892 is 795664\n",
      "The squre of 893 is 797449\n",
      "The squre of 894 is 799236\n",
      "The squre of 895 is 801025\n",
      "The squre of 896 is 802816\n",
      "The squre of 897 is 804609\n",
      "The squre of 898 is 806404\n",
      "The squre of 899 is 808201\n",
      "The squre of 900 is 810000\n",
      "The squre of 901 is 811801\n",
      "The squre of 902 is 813604\n",
      "The squre of 903 is 815409\n",
      "The squre of 904 is 817216\n",
      "The squre of 905 is 819025\n",
      "The squre of 906 is 820836\n",
      "The squre of 907 is 822649\n",
      "The squre of 908 is 824464\n",
      "The squre of 909 is 826281\n",
      "The squre of 910 is 828100\n",
      "The squre of 911 is 829921\n",
      "The squre of 912 is 831744\n",
      "The squre of 913 is 833569\n",
      "The squre of 914 is 835396\n",
      "The squre of 915 is 837225\n",
      "The squre of 916 is 839056\n",
      "The squre of 917 is 840889\n",
      "The squre of 918 is 842724\n",
      "The squre of 919 is 844561\n",
      "The squre of 920 is 846400\n",
      "The squre of 921 is 848241\n",
      "The squre of 922 is 850084\n",
      "The squre of 923 is 851929\n",
      "The squre of 924 is 853776\n",
      "The squre of 925 is 855625\n",
      "The squre of 926 is 857476\n",
      "The squre of 927 is 859329\n",
      "The squre of 928 is 861184\n",
      "The squre of 929 is 863041\n",
      "The squre of 930 is 864900\n",
      "The squre of 931 is 866761\n",
      "The squre of 932 is 868624\n",
      "The squre of 933 is 870489\n",
      "The squre of 934 is 872356\n",
      "The squre of 935 is 874225\n",
      "The squre of 936 is 876096\n",
      "The squre of 937 is 877969\n",
      "The squre of 938 is 879844\n",
      "The squre of 939 is 881721\n",
      "The squre of 940 is 883600\n",
      "The squre of 941 is 885481\n",
      "The squre of 942 is 887364\n",
      "The squre of 943 is 889249\n",
      "The squre of 944 is 891136\n",
      "The squre of 945 is 893025\n",
      "The squre of 946 is 894916\n",
      "The squre of 947 is 896809\n",
      "The squre of 948 is 898704\n",
      "The squre of 949 is 900601\n",
      "The squre of 950 is 902500\n",
      "The squre of 951 is 904401\n",
      "The squre of 952 is 906304\n",
      "The squre of 953 is 908209\n",
      "The squre of 954 is 910116\n",
      "The squre of 955 is 912025\n",
      "The squre of 956 is 913936\n",
      "The squre of 957 is 915849\n",
      "The squre of 958 is 917764\n",
      "The squre of 959 is 919681\n",
      "The squre of 960 is 921600\n",
      "The squre of 961 is 923521\n",
      "The squre of 962 is 925444\n",
      "The squre of 963 is 927369\n",
      "The squre of 964 is 929296\n",
      "The squre of 965 is 931225\n",
      "The squre of 966 is 933156\n",
      "The squre of 967 is 935089\n",
      "The squre of 968 is 937024\n",
      "The squre of 969 is 938961\n",
      "The squre of 970 is 940900\n",
      "The squre of 971 is 942841\n",
      "The squre of 972 is 944784\n",
      "The squre of 973 is 946729\n",
      "The squre of 974 is 948676\n",
      "The squre of 975 is 950625\n",
      "The squre of 976 is 952576\n",
      "The squre of 977 is 954529\n",
      "The squre of 978 is 956484\n",
      "The squre of 979 is 958441\n",
      "The squre of 980 is 960400\n",
      "The squre of 981 is 962361\n",
      "The squre of 982 is 964324\n",
      "The squre of 983 is 966289\n",
      "The squre of 984 is 968256\n",
      "The squre of 985 is 970225\n",
      "The squre of 986 is 972196\n",
      "The squre of 987 is 974169\n",
      "The squre of 988 is 976144\n",
      "The squre of 989 is 978121\n",
      "The squre of 990 is 980100\n",
      "The squre of 991 is 982081\n",
      "The squre of 992 is 984064\n",
      "The squre of 993 is 986049\n",
      "The squre of 994 is 988036\n",
      "The squre of 995 is 990025\n",
      "The squre of 996 is 992016\n",
      "The squre of 997 is 994009\n",
      "The squre of 998 is 996004\n",
      "The squre of 999 is 998001\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for n in range(1000):\n",
    "    print(\"The squre of\", n ,\"is\", n*n)\n",
    "    pass\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first input is 248\n",
      "second input is 471\n",
      "average is 359.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "359.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg(x,y):\n",
    "    print(\"first input is\", x)\n",
    "    print(\"second input is\", y)\n",
    "    a=(x+y)/2.0\n",
    "    print(\"average is\",a)\n",
    "    return a\n",
    "avg(248,471)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f2ac5c36b616>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-f2ac5c36b616>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import numpy.zeros([3,2])\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy.zeros([3,2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "a=numpy.zeros([3,2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.]\n",
      " [  9.   0.]\n",
      " [  0.  12.]]\n"
     ]
    }
   ],
   "source": [
    "a[0,0]=1\n",
    "a[0,1]=2\n",
    "a[1,0]=9\n",
    "a[2,1]=12\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "print(a[0,1])\n",
    "v=a[1,0]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f439c6c4f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "a[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2619d71a518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAAD8CAYAAAAsetuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDYMhNQyG1Ph/0zJBf9aCak4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2619d458e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(a, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2619d8e87f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAAD8CAYAAAAsetuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDYMhNQyG1Ph/0zJBf9aCak4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2619d69ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f38021ca65b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imshow' is not defined"
     ]
    }
   ],
   "source": [
    "imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#개 객체를 위한 클래스\n",
    "class dog:\n",
    "    # 개는 짓을 수 있습니다.(bark)\n",
    "    def bark(self):\n",
    "        print(\"woof!\")\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    # 개는 짓을 수 있습니다.(bark)\n",
    "    def bark(self):\n",
    "        print(\"woof!\")\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woof!\n"
     ]
    }
   ],
   "source": [
    "sizzles = Dog()\n",
    "sizzles.bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woof!\n",
      "woof!\n"
     ]
    }
   ],
   "source": [
    "# sizzles는 우리로 치면 바둑이의 영어 표현이다.\n",
    "# sizzles.bark() 의 형태는 통해 우리는 sizzles 객체에 대해 bark()함수를 호출할 수 있다.\n",
    "\n",
    "mutely=Dog()\n",
    "mutely.bark()\n",
    "sizzles.bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, petname, temp):\n",
    "        self.name=petname\n",
    "        self.temperature=temp\n",
    "    \n",
    "    def status(self):\n",
    "        print(\"dog nams is\", self.name)\n",
    "        print(\"dog temperature is\", self.temperature)\n",
    "        pass\n",
    "    \n",
    "    def setTemperature(self, temp):\n",
    "        self.temmperature=temp\n",
    "        pass\n",
    "    def bark(self):\n",
    "        print(\"woof!\")\n",
    "        pass\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 37\n"
     ]
    }
   ],
   "source": [
    "# Dog 클래스에서 새로운 멍멍이 객체를 생성한다.\n",
    "lassie = Dog(\"Lassie\",37)\n",
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lessie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-33b4ceddc8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlessie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetTemperature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lessie' is not defined"
     ]
    }
   ],
   "source": [
    "lessie.setTemperature(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassie.setTemperature(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lessie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cdafb85b8a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlessie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lessie' is not defined"
     ]
    }
   ],
   "source": [
    "lessie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'status' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-33d0f08045e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlassie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'status' is not defined"
     ]
    }
   ],
   "source": [
    "lassie(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 37\n"
     ]
    }
   ],
   "source": [
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 37\n"
     ]
    }
   ],
   "source": [
    "lassie.setTemperature(40)\n",
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassie = Dog(\"Lassie\",38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 38\n"
     ]
    }
   ],
   "source": [
    "lassie.setTemperature(40)\n",
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    def __init__(self, petname, temp):\n",
    "        self.name=petname;\n",
    "        self.temperature=temp;\n",
    "    \n",
    "    def status(self):\n",
    "        print(\"dog nams is\", self.name)\n",
    "        print(\"dog temperature is\", self.temperature)\n",
    "        pass\n",
    "    \n",
    "    def setTemperature(self, temp):\n",
    "        self.temmperature=temp;\n",
    "        pass\n",
    "    def bark(self):\n",
    "        print(\"woof!\")\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 38\n"
     ]
    }
   ],
   "source": [
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog nams is Lassie\n",
      "dog temperature is 38\n"
     ]
    }
   ],
   "source": [
    "lassie.setTemperature(40)\n",
    "lassie.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        pass\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "    self.indoes = inputnodes\n",
    "    self.hnodes = hiddennodes\n",
    "    self.onodes = outputnodes\n",
    "    \n",
    "    #학습률\n",
    "    self.lr = learningrate\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-37-20b1395177fd>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-20b1395177fd>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    self.inodes = inputnodes\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "    self.inodes = inputnodes\n",
    "    self.hnodes = hiddennodes\n",
    "    self.onodes = outputnodes\n",
    "    \n",
    "    #학습률\n",
    "    self.lr = learningrate\n",
    "    pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3\n",
    "hidden_nodes=3\n",
    "output_nodes=3\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08719135,  0.36797133,  0.62575117,  0.11446472,  0.94252563,\n",
       "         0.22462807,  0.42998833,  0.63221546,  0.13104844,  0.16193686],\n",
       "       [ 0.33009544,  0.83459923,  0.17103719,  0.13771191,  0.12382272,\n",
       "         0.68358837,  0.42379747,  0.56517235,  0.35535618,  0.03400898],\n",
       "       [ 0.86156973,  0.47729978,  0.25340842,  0.38232294,  0.73514345,\n",
       "         0.14926265,  0.54071318,  0.75338253,  0.28875482,  0.32589078],\n",
       "       [ 0.87509091,  0.79235514,  0.05848936,  0.33704845,  0.83430591,\n",
       "         0.83041218,  0.41405758,  0.24062527,  0.33917166,  0.957145  ],\n",
       "       [ 0.6731399 ,  0.62309381,  0.93806859,  0.25437984,  0.69654431,\n",
       "         0.36417733,  0.37893797,  0.13830185,  0.12317093,  0.00489657],\n",
       "       [ 0.64288087,  0.32949375,  0.3060165 ,  0.15956748,  0.79228478,\n",
       "         0.88515832,  0.85270433,  0.56086324,  0.50238333,  0.16970475],\n",
       "       [ 0.55277609,  0.90804178,  0.79067328,  0.18775124,  0.03185805,\n",
       "         0.54783511,  0.77244558,  0.50679499,  0.39332861,  0.3393891 ],\n",
       "       [ 0.68128607,  0.08056437,  0.52993268,  0.21888151,  0.60471481,\n",
       "         0.96680652,  0.24469125,  0.44385461,  0.93991875,  0.2232927 ],\n",
       "       [ 0.224543  ,  0.63404018,  0.6871613 ,  0.67552473,  0.69769089,\n",
       "         0.96377662,  0.94084236,  0.0131014 ,  0.90551755,  0.76448956],\n",
       "       [ 0.89863635,  0.07995794,  0.89041712,  0.11449179,  0.93422879,\n",
       "         0.74389494,  0.14872492,  0.64024561,  0.13223273,  0.60409896]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44965027,  0.18290516,  0.23896644,  0.73882977,  0.91764103,\n",
       "         0.12908194,  0.14887336,  0.0381448 ],\n",
       "       [ 0.02206855,  0.72600514,  0.13408976,  0.57878999,  0.12060623,\n",
       "         0.3305607 ,  0.31068442,  0.08651354],\n",
       "       [ 0.13545511,  0.65455838,  0.14417067,  0.37811477,  0.20346363,\n",
       "         0.4963151 ,  0.86125758,  0.6139747 ],\n",
       "       [ 0.9007974 ,  0.47494358,  0.51083099,  0.16766834,  0.56595822,\n",
       "         0.21324644,  0.78162711,  0.34040201]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56330718,  0.80090985,  0.99040803,  0.99927804],\n",
       "       [ 0.9264972 ,  0.25699193,  0.89016713,  0.76651017],\n",
       "       [ 0.9860238 ,  0.69912997,  0.74122552,  0.92927606],\n",
       "       [ 0.16902236,  0.72642052,  0.90956271,  0.93430847],\n",
       "       [ 0.40556398,  0.0693129 ,  0.59920189,  0.20447065],\n",
       "       [ 0.55373962,  0.8671588 ,  0.75167861,  0.58782761],\n",
       "       [ 0.91876468,  0.53647523,  0.07627936,  0.53321929],\n",
       "       [ 0.66983643,  0.50191176,  0.90042106,  0.63180752]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41421746, -0.19429681,  0.2684616 , -0.29410231, -0.47013526,\n",
       "         0.08931873,  0.12721695, -0.49833155],\n",
       "       [ 0.34300428,  0.2368926 ,  0.35137231,  0.04014984,  0.43957298,\n",
       "        -0.35701645,  0.21356364, -0.19411982],\n",
       "       [ 0.35229313,  0.33552615,  0.01258298,  0.48866367,  0.37271018,\n",
       "         0.46509625, -0.46547166,  0.43867454],\n",
       "       [-0.33239998, -0.14094248,  0.01256577,  0.46620631,  0.28960883,\n",
       "        -0.030651  , -0.08408276, -0.14528151]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(4,8)-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18879175,  0.04453985,  0.03723692],\n",
       "       [-0.19423158,  0.08816677, -0.40048502],\n",
       "       [ 0.00339485,  0.47530433, -0.15260759]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(3,3)-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a4378afd8484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m# w11 w21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#w12 w 22 등이 될 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "# 가중치 행렬 wih와 who\n",
    "#배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "# w11 w21\n",
    "#w12 w 22 등이 될 것\n",
    "self.wih = (numpy.random.rand(self.hnodes,self.inodes)-0.5)\n",
    "self.who = (numpy.random.rand(self.onodes,self.hnodes)-0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-9c72472cf91e>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-9c72472cf91e>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    self.who = (numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.hnodes, self.hnodes))\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = (numpy.random.rand(0.0, pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = (numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.hnodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-9c72472cf91e>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-9c72472cf91e>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    self.who = (numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.hnodes, self.hnodes))\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = (numpy.random.rand(0.0, pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = (numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.hnodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scipy를 통해 시그모이드 함수인 expit()를 사용할 수 있게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#시작 전에 필요한 라이브러리를 불러와야 한다.\n",
    "import numpy\n",
    "import scipy.special\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = numpy.random.rand(0.0, pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.onodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "                    \n",
    "        self.activation_function = lambda x:scipy.expit(x) \n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query():\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin =2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_outputs)\n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return(final_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-40fa6cfc735d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m#신경망의 인스턴스를 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-2963af9fc5cf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputnodes, hiddennodes, outputnodes, learningrate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;31m# w11 w21 w21 w22 등이 될 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.rand (numpy\\random\\mtrand\\mtrand.c:18928)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample (numpy\\random\\mtrand\\mtrand.c:14895)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array (numpy\\random\\mtrand\\mtrand.c:2383)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3\n",
    "hidden_nodes=3\n",
    "output_nodes=3\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-40fa6cfc735d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m#신경망의 인스턴스를 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-12b611201568>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputnodes, hiddennodes, outputnodes, learningrate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;31m# w11 w21 w21 w22 등이 될 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.rand (numpy\\random\\mtrand\\mtrand.c:18928)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample (numpy\\random\\mtrand\\mtrand.c:14895)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array (numpy\\random\\mtrand\\mtrand.c:2383)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3\n",
    "hidden_nodes=3\n",
    "output_nodes=3\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#시작 전에 필요한 라이브러리를 불러와야 한다.\n",
    "import numpy\n",
    "import scipy.special\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = numpy.random.rand(0.0,pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.rand(0.0,pow(self.onodes,-0.5),(self.onodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "                    \n",
    "        self.activation_function = lambda x:scipy.expit(x) \n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query(self, inputs_list):\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin =2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_outputs)\n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return(final_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-a0d5fc19cdc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m#신경망의 인스턴스를 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-2963af9fc5cf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputnodes, hiddennodes, outputnodes, learningrate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;31m# w11 w21 w21 w22 등이 될 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.rand (numpy\\random\\mtrand\\mtrand.c:18928)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample (numpy\\random\\mtrand\\mtrand.c:14895)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array (numpy\\random\\mtrand\\mtrand.c:2383)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3.0\n",
    "hidden_nodes=3.0\n",
    "output_nodes=3.0\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a0d5fc19cdc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m#신경망의 인스턴스를 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-2963af9fc5cf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputnodes, hiddennodes, outputnodes, learningrate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[1;31m# w11 w21 w21 w22 등이 될 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.rand (numpy\\random\\mtrand\\mtrand.c:18928)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample (numpy\\random\\mtrand\\mtrand.c:14895)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array (numpy\\random\\mtrand\\mtrand.c:2383)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3.0\n",
    "hidden_nodes=3.0\n",
    "output_nodes=3.0\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "query() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-1e8d927e7cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: query() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#시작 전에 필요한 라이브러리를 불러와야 한다.\n",
    "import numpy\n",
    "#시그모이드 함수 expit() 적용을 위해 scipy.special로 불러오기\n",
    "import scipy.special\n",
    "#행렬을 시각화 하기 위한 라이브러리\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "        #활성화 함수로는 시그모이드 함수를 이용            \n",
    "        self.activation_function = lambda x:scipy.special.expit(x) \n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #입력 리스트를 2차원의 행렬로 변환\n",
    "        inputs=numpy.array(inputs_list, ndim=2).T\n",
    "        targets=numpy.array(targets_list, ndim=2).T\n",
    "        #은닉계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        #은닉계층에서 나가는 신호를 계산\n",
    "        hidden_outputs= self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #최종 출력계층으로 들어오는 신호를 계산\n",
    "        final_inputs= numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        #오차는 실제 값- 계산 값\n",
    "        output_errors = targets - final_outputs\n",
    "        #은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        #은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who+=self.lr*numpy.dot((output_errors*final_outputs*(1.0-final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        #은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.wih+=self.lr*numpy.dot((output_errors*hidden_outputs*(1.0-hidden_outputs)), numpy.transpose(inputs))\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query(self, inputs_list):\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin =2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return(final_outputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\totti\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "#입출력의 노드 수\n",
    "input_nodes=3.0\n",
    "hidden_nodes=3.0\n",
    "output_nodes=3.0\n",
    "\n",
    "# 학습률은 0.3으로 정의해보자\n",
    "learning_rate =0.3\n",
    "\n",
    "#신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42080894],\n",
       "       [ 0.51919835],\n",
       "       [ 0.58567569]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file =open(\"ipython/mnist_train_100.csv\",'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,118,219,166,118,118,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,242,254,254,254,254,254,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,232,254,254,254,254,254,238,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,104,244,254,224,254,254,254,141,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,207,254,210,254,254,254,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,206,254,254,254,254,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,209,254,254,254,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,91,137,253,254,254,254,112,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,214,250,254,254,254,254,254,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,247,254,254,254,254,254,254,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,246,254,254,254,254,254,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,89,89,93,240,254,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,128,254,219,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,214,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,138,254,254,116,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,177,90,0,0,0,0,0,25,240,254,254,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,164,254,215,63,36,0,51,89,206,254,254,139,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,57,197,254,254,222,180,241,254,254,253,213,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,140,105,254,254,254,254,254,254,236,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,117,117,165,254,254,239,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22796f91470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22794b3a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[1].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap ='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_values = data_list[0].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.02164706\n",
      "  0.07988235  0.07988235  0.07988235  0.49917647  0.538       0.68941176\n",
      "  0.11094118  0.65447059  1.          0.96894118  0.50305882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.12647059  0.14976471  0.37494118\n",
      "  0.60788235  0.67        0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.88352941  0.67776471  0.99223529  0.94952941  0.76705882\n",
      "  0.25847059  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.20023529\n",
      "  0.934       0.99223529  0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.98447059  0.37105882  0.32835294\n",
      "  0.32835294  0.22741176  0.16141176  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.07988235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.71658824  0.96894118  0.94564706\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.32058824  0.61564706\n",
      "  0.42541176  0.99223529  0.99223529  0.80588235  0.05270588  0.01\n",
      "  0.17694118  0.60788235  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.06435294  0.01388235  0.60788235  0.99223529  0.35941176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.54964706  0.99223529  0.74764706  0.01776471\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.05270588  0.74764706  0.99223529\n",
      "  0.28176471  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.14588235\n",
      "  0.94564706  0.88352941  0.63117647  0.42929412  0.01388235  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32447059  0.94176471  0.99223529  0.99223529  0.472       0.10705882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.18470588  0.73211765  0.99223529  0.99223529\n",
      "  0.59235294  0.11482353  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.07211765  0.37105882\n",
      "  0.98835294  0.99223529  0.736       0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.97670588  0.99223529  0.97670588  0.25847059  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.18858824  0.51470588\n",
      "  0.72047059  0.99223529  0.99223529  0.81364706  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.16141176  0.58458824  0.89905882\n",
      "  0.99223529  0.99223529  0.99223529  0.98058824  0.71658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.10317647  0.45258824  0.868       0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.79035294  0.31282353  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.09929412  0.26623529  0.83694118  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.32447059  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.07988235  0.67388235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.76705882  0.32058824  0.04494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.22352941  0.67776471  0.88741176  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.95729412  0.52635294  0.05270588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.538       0.99223529  0.99223529  0.99223529  0.83305882\n",
      "  0.53411765  0.52247059  0.07211765  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onodes = 10\n",
    "targets = numpy.zeros(onodes)+0.01\n",
    "targets[int(all_values[0])]=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#시작 전에 필요한 라이브러리를 불러와야 한다.\n",
    "import numpy\n",
    "#시그모이드 함수 expit() 적용을 위해 scipy.special로 불러오기\n",
    "import scipy.special\n",
    "#행렬을 시각화 하기 위한 라이브러리\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화하기\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        #배열 내 가중치는 w_i_j 로 표기, 노드i 에서 다음 계층의 노드 j로 연결됨을 의미함\n",
    "        # w11 w21 w21 w22 등이 될 것\n",
    "        \n",
    "        self.wih = numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes, self.hnodes))\n",
    "        \n",
    "                   #위의 업데이트를 통해 가중치를 정교화 할 수 있다.정규분포의 중심을 0.0으로 설정하면서\n",
    "                   # 노드로 들어오는 견결 노드의 개수에 루트를 씌우고 역수를 취하는 pow 함수를 적용하였다.\n",
    "\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "        #활성화 함수로는 시그모이드 함수를 이용            \n",
    "        self.activation_function = lambda x:scipy.special.expit(x) \n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #입력 리스트를 2차원의 행렬로 변환\n",
    "        inputs=numpy.array(inputs_list, ndim=2).T\n",
    "        targets=numpy.array(targets_list, ndim=2).T\n",
    "        #은닉계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        #은닉계층에서 나가는 신호를 계산\n",
    "        hidden_outputs= self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #최종 출력계층으로 들어오는 신호를 계산\n",
    "        final_inputs= numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        #오차는 실제 값- 계산 값\n",
    "        output_errors = targets - final_outputs\n",
    "        #은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        #은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who+=self.lr*numpy.dot((output_errors*final_outputs*(1.0-final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        #은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.wih+=self.lr*numpy.dot((output_errors*hidden_outputs*(1.0-hidden_outputs)), numpy.transpose(inputs))\n",
    "        pass\n",
    "    \n",
    "    #신경망에 질의하기\n",
    "    def query(self, inputs_list):\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin =2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    #입력, 은닉, 출력 노드의 수\n",
    "    input_nodes=784\n",
    "    hidden_nodes =100\n",
    "    output_nodes =10\n",
    "    \n",
    "    #학습률은 0.3\n",
    "    learning_rate =0.3\n",
    "    \n",
    "    #신경망의 인스턴스 생성\n",
    "    n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "    \n",
    "    #mnist 학습 데이터인 csv 파일을 리스트로 불러오기\n",
    "    training_data_file = open(\"mnist_dataset/mnist_train_100.csv\",'r')\n",
    "    training_data_list = training_data_file.readlines()\n",
    "    training_data_file.close()\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    \n",
    "    #학습 데이터 모음 내의 모든 레코드 검색\n",
    "    for record in training_data_list:\n",
    "        #레코드를 쉼표에 의해 분리\n",
    "        all_values = record.split(',')\n",
    "        #입력 값의 범위와 값 조정\n",
    "        inputs =(numpy.asfarray(all_values[1:])/255*0.99)+0.01\n",
    "        #결과 값 생성(실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = numpy.zeros(output_nodes)+0.01\n",
    "        #all_values[0]는 이 레코드에 대한 결과 값\n",
    "        targets[int(all_values[0])]=0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
